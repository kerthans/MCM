import json
import pandas as pd
import numpy as np
from pathlib import Path
from rich.console import Console
from rich.table import Table
from sklearn import clone
from sklearn.model_selection import ParameterGrid, TimeSeriesSplit
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import xgboost as xgb
import lightgbm as lgb
from typing import Dict, List, Tuple
import joblib
from scipy import stats
from scipy.optimize import minimize
from rich.progress import Progress
from src.visualization.OlympicVisualizer import OlympicVisualizer
class OlympicMedalPredictor:
    def __init__(self):
        self.console = Console()
        self.visualizer = OlympicVisualizer()
        self.models = {
            'gbm': GradientBoostingRegressor(
                n_estimators=200,
                learning_rate=0.05,
                max_depth=4,
                random_state=42
            ),
            'rf': RandomForestRegressor(
                n_estimators=200,
                max_depth=6, 
                random_state=42
            ),
            'xgb': xgb.XGBRegressor(
                n_estimators=200,
                learning_rate=0.05,
                max_depth=4,
                random_state=42
            ),
            'lgb': lgb.LGBMRegressor(
                n_estimators=200,
                learning_rate=0.05,
                max_depth=3,  # é™ä½æ ‘æ·±åº¦
                min_child_samples=30,  # æé«˜åˆ†è£‚æœ€å°æ ·æœ¬é‡
                min_child_weight=0.1,  # é™ä½åˆ†è£‚é˜ˆå€¼
                reg_lambda=0.5,  # é™ä½L2æ­£åˆ™å¼ºåº¦
                reg_alpha=0.1,  # å¢åŠ L1æ­£åˆ™
                num_leaves=15,  # é™åˆ¶å¶å­èŠ‚ç‚¹æ•°
                random_state=42
            )
        }
        self.r2_scores = {
            'Gold': {model_name: [] for model_name in self.models.keys()},
            'Total': {model_name: [] for model_name in self.models.keys()}
        }
        self.model_weights = {}
        self.feature_importance = {}
        self.predictions_store = {}
        
    def prepare_data(self, features_df: pd.DataFrame, historical_data: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, pd.Series], List[str]]:
        """å¼ºåŒ–çš„æ•°æ®å‡†å¤‡å‡½æ•°ï¼Œå¤„ç†æ— ç©·å€¼å’Œå¼‚å¸¸å€¼"""
        from sklearn.impute import SimpleImputer
        import numpy as np
        
        df = features_df.merge(
            historical_data[['NOC', 'Year', 'Gold', 'Total']], 
            on=['NOC', 'Year'], 
            how='left'
        )
        
        # å¤„ç†å†å²è¶‹åŠ¿ç‰¹å¾
        for col in ['Gold', 'Total']:
            # ç§»åŠ¨å¹³å‡ï¼Œä½¿ç”¨min_periodsé¿å…NaN
            df[f'{col}_ma_4year'] = df.groupby('NOC')[col].transform(
                lambda x: x.rolling(4, min_periods=1).mean()
            ).fillna(0)
            
            # å®‰å…¨çš„å¢é•¿ç‡è®¡ç®—
            def safe_pct_change(x):
                change = x.pct_change(4)
                # å°†infæ›¿æ¢ä¸ºä¸Šé™å€¼
                change = change.replace([np.inf, -np.inf], np.nan)
                # ä½¿ç”¨90åˆ†ä½æ•°ä½œä¸ºæå€¼ä¸Šé™
                upper_bound = np.nanpercentile(change, 90)
                return change.clip(lower=-1, upper=upper_bound)
                
            df[f'{col}_growth'] = df.groupby('NOC')[col].transform(safe_pct_change).fillna(0)
            df[f'historical_max_{col}'] = df.groupby('NOC')[col].transform('max').fillna(0)
        
        # åˆ†å±‚æ ‡ç­¾
        tier_1_countries = ['United States', 'China', 'Great Britain', 'Japan', 'Australia']
        tier_2_countries = ['France', 'Germany', 'Italy', 'Netherlands', 'South Korea']
        df['country_tier'] = (
            df['NOC'].apply(
                lambda x: 1 if x in tier_1_countries else (2 if x in tier_2_countries else 3)
            )
            .astype(int)  # å¼ºåˆ¶è½¬æ¢ä¸ºæ•´æ•°ç±»å‹
        )
        
        # ä¿å­˜NOCåˆ—
        noc_series = df['NOC']
        
        # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡å˜é‡
        target_cols = ['Gold', 'Total']
        exclude_cols = ['NOC'] + target_cols
        feature_cols = [col for col in df.columns if col not in exclude_cols]
        
        # æå–ç‰¹å¾çŸ©é˜µ
        X = df[feature_cols].copy()
        
        # å¤„ç†æ•°å€¼å‹ç‰¹å¾
        num_cols = X.select_dtypes(include=['int64', 'float64']).columns
        if len(num_cols) > 0:
            # å…ˆå¤„ç†æ— ç©·å€¼
            X[num_cols] = X[num_cols].replace([np.inf, -np.inf], np.nan)
            # ä½¿ç”¨ä¸­ä½æ•°å¡«å……ç¼ºå¤±å€¼
            num_imputer = SimpleImputer(strategy='median')
            X[num_cols] = num_imputer.fit_transform(X[num_cols])
        
        # ç±»åˆ«å‹ç‰¹å¾å¤„ç†
        cat_cols = X.select_dtypes(include=['object', 'category']).columns
        if len(cat_cols) > 0:
            cat_imputer = SimpleImputer(strategy='most_frequent')
            X[cat_cols] = cat_imputer.fit_transform(X[cat_cols])
        
        # æœ€ç»ˆæ•°æ®ç±»å‹è½¬æ¢å’Œæ¸…ç†
        X = X.astype(float)
        
        # ç¡®ä¿æ²¡æœ‰å¼‚å¸¸å€¼
        for col in X.columns:
            upper_bound = np.percentile(X[col], 99)
            lower_bound = np.percentile(X[col], 1)
            X[col] = X[col].clip(lower_bound, upper_bound)
        
        y = {
            'Gold': df['Gold'].fillna(0).astype(float),
            'Total': df['Total'].fillna(0).astype(float)
        }
        
        return X, y, feature_cols
    


    def _optimize_ensemble_weights(self, 
                                predictions: Dict[str, np.ndarray], 
                                target: pd.Series,
                                base_scores: Dict[str, float],
                                constraints: Dict) -> Dict[str, float]:
        """ä¼˜åŒ–é›†æˆæƒé‡ï¼Œè€ƒè™‘å†å²çº¦æŸ"""
        def objective(w):
            w = w / w.sum()
            ensemble_pred = np.zeros_like(list(predictions.values())[0])
            for i, (_, pred) in enumerate(predictions.items()):
                ensemble_pred += w[i] * pred
            
            # æ·»åŠ çº¦æŸæƒ©ç½š
            penalty = 0
            if ensemble_pred.sum() < constraints['total_range'][0]:
                penalty += (constraints['total_range'][0] - ensemble_pred.sum()) ** 2
            elif ensemble_pred.sum() > constraints['total_range'][1]:
                penalty += (ensemble_pred.sum() - constraints['total_range'][1]) ** 2
            
            return -r2_score(target, ensemble_pred) + penalty * 0.1
        
        n_models = len(predictions)
        weights = np.array([base_scores[model] for model in predictions.keys()])
        weights = weights / weights.sum()
        
        constraints_opt = (
            {'type': 'eq', 'fun': lambda w: np.sum(w) - 1},
        )
        bounds = [(0, 1) for _ in range(n_models)]
        
        result = minimize(
            objective, 
            weights, 
            method='SLSQP',
            constraints=constraints_opt,
            bounds=bounds,
            options={'maxiter': 1000}
        )
        
        optimized_weights = result.x / result.x.sum()
        return dict(zip(predictions.keys(), optimized_weights))

    def _calculate_weights(self, scores: Dict[str, float]) -> Dict[str, float]:
        """æ”¹è¿›çš„æƒé‡è®¡ç®—ï¼Œå¼•å…¥æŒ‡æ•°åŠ æƒ"""
        # è®¡ç®—ç›¸å¯¹æ€§èƒ½å¾—åˆ†
        max_score = max(scores.values())
        exp_scores = {k: np.exp(5 * (v / max_score - 1)) for k, v in scores.items()}  # æŒ‡æ•°æ”¾å¤§å·®å¼‚
        total = sum(exp_scores.values())
        return {k: v / total for k, v in exp_scores.items()}

    def train_models(self, X: pd.DataFrame, y: Dict[str, pd.Series]) -> Dict:
        trained_models = {}
        scores = {}

        param_grid = {
            'gbm': {'n_estimators': [200, 300], 'learning_rate': [0.03, 0.05], 'max_depth': [3, 4, 5]},
            'rf': {'n_estimators': [200, 300], 'max_depth': [4, 6, 8], 'min_samples_split': [2, 5]},
            'xgb': {'n_estimators': [200, 300], 'learning_rate': [0.03, 0.05], 'max_depth': [3, 4, 5]},
            'lgb': {'n_estimators': [200, 300], 'learning_rate': [0.03, 0.05], 'max_depth': [3, 4, 5],
                    'min_child_samples': [15, 20, 25]}
        }

        def fit_model(model, X_train, y_train, X_val=None, y_val=None, model_name=None):
            if model_name == 'xgb':
                model.fit(X_train, y_train, eval_set=[(X_val, y_val)] if X_val is not None else None,
                          verbose=False)
            elif model_name == 'lgb':
                model.fit(X_train, y_train, eval_set=[(X_val, y_val)] if X_val is not None else None,
                          callbacks=[lgb.early_stopping(10, verbose=False)] if X_val is not None else None)
            else:
                model.fit(X_train, y_train)
            return model

        cv_split = TimeSeriesSplit(n_splits=5)

        for target_name, target in y.items():
            if target is None:
                continue

            trained_models[target_name] = {}
            scores[target_name] = {}

            for model_name, model in self.models.items():
                print(f"\nTraining {model_name} for {target_name}")
                best_score = float('-inf')
                best_params = None
                cv_r2_scores = []  # ç”¨äºå­˜å‚¨æ¯ä¸ªæŠ˜çš„RÂ²åˆ†æ•°
                for params in ParameterGrid(param_grid[model_name]):
                    cv_scores = []
                    for train_idx, val_idx in cv_split.split(X):
                        cv_model = clone(model)
                        cv_model.set_params(**params)

                        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
                        y_train, y_val = target.iloc[train_idx], target.iloc[val_idx]

                        cv_model = fit_model(cv_model, X_train, y_train, X_val, y_val, model_name)
                        pred = cv_model.predict(X_val)
                        score = r2_score(y_val, pred)
                        cv_scores.append(score)
                        if len(cv_scores) == len(cv_r2_scores) + 1 and np.mean(cv_scores) > best_score:
                            cv_r2_scores = cv_scores.copy()
                    avg_score = np.mean(cv_scores)
                    print(f"Score: {avg_score:.4f}")
                    if avg_score > best_score:
                        best_score = avg_score
                        best_params = params
                self.r2_scores[target_name][model_name] = cv_r2_scores
                final_model = clone(model)
                final_model.set_params(**best_params)
                final_model = fit_model(final_model, X, target, model_name=model_name)

                trained_models[target_name][model_name] = final_model
                scores[target_name][model_name] = best_score

                if hasattr(final_model, 'feature_importances_'):
                    self.feature_importance[f"{target_name}_{model_name}"] = pd.Series(
                        final_model.feature_importances_,
                        index=X.columns
                    ).sort_values(ascending=False)
                    print("\nTop 5 features:")
                    print(self.feature_importance[f"{target_name}_{model_name}"].head())

            self.model_weights[target_name] = self._calculate_weights(scores[target_name])
            print(f"\nWeights: {self.model_weights[target_name]}")

        return trained_models

    def _calculate_optimal_weights(self, predictions: Dict, scores: Dict) -> Dict[str, float]:
        """è®¡ç®—æœ€ä¼˜æƒé‡"""
        base_weights = np.array([scores[model] for model in predictions.keys()])
        weights = base_weights / np.sum(base_weights)
        
        # éªŒè¯é¢„æµ‹ç»“æœçš„è¡¨ç°
        ensemble_predictions = np.zeros_like(list(predictions.values())[0]['predictions'])
        for i, (model_name, _) in enumerate(predictions.items()):
            ensemble_predictions += weights[i] * predictions[model_name]['predictions']
        
        # è¿”å›å½’ä¸€åŒ–çš„æƒé‡
        return dict(zip(predictions.keys(), weights))

    def predict_with_uncertainty(self, X_pred: pd.DataFrame, models: Dict, target_name: str, n_iterations: int = 100) -> \
            Tuple[np.ndarray, np.ndarray]:
        class StrictConstraint:
            def __init__(self, target_name):
                # å›½å®¶åç§°æ˜ å°„
                self.country_mapping = {
                    'United States': ['USA', 'United States', 'United States of America'],
                    'Great Britain': ['GBR', 'Great Britain', 'United Kingdom'],
                    'China': ['CHN', 'China', "People's Republic of China"],
                    'Japan': ['JPN', 'Japan'],
                    'Australia': ['AUS', 'Australia']
                }

                self.targets = {
                    'Gold': {'total': 340, 'range': (335, 342)},
                    'Total': {'total': 1080, 'range': (1070, 1085)}
                }[target_name]
                self.min_allow = 0.99
                self.max_allow = 1.01

                self.country_ratios = {
                    'Gold': {
                        'China_vs_US': (0.92, 0.95),
                        'GB_vs_China': (0.65, 0.75),
                        'Japan_vs_GB': (0.7, 0.8),
                        'ROW_vs_Top5': (0.45, 0.55)
                    },
                    'Total': {
                        'medal_to_gold_ratio': {
                            1: (2.9, 3.1),
                            2: (3.0, 3.3),
                            3: (3.2, 3.5)
                        }
                    }
                }

            def get_country_index(self, country: str, country_names) -> int:
                """å®‰å…¨è·å–å›½å®¶ç´¢å¼•"""
                try:
                    # ç›´æ¥å°è¯•è·å–ç´¢å¼•
                    return country_names.get_loc(country)
                except KeyError:
                    # æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„åˆ«å
                    for master_name, aliases in self.country_mapping.items():
                        if country in aliases:
                            for alias in aliases:
                                try:
                                    return country_names.get_loc(alias)
                                except KeyError:
                                    continue
                    # å¦‚æœæ‰¾ä¸åˆ°ä»»ä½•åŒ¹é…ï¼Œè¿”å›-1
                    return -1

            def adjust_prediction(self, ensemble_pred, country_names, tiers):
                adjusted = ensemble_pred.copy()

                # è·å–ä¸»è¦å›½å®¶ç´¢å¼•
                us_idx = self.get_country_index('United States', country_names)
                cn_idx = self.get_country_index('China', country_names)
                gb_idx = self.get_country_index('Great Britain', country_names)
                jp_idx = self.get_country_index('Japan', country_names)

                # åªæœ‰å½“æ‰€æœ‰å¿…è¦çš„å›½å®¶éƒ½æ‰¾åˆ°æ—¶æ‰åº”ç”¨çº¦æŸ
                if all(idx != -1 for idx in [us_idx, cn_idx]):
                    cn_ratio = adjusted[cn_idx] / adjusted[us_idx]

                    if cn_ratio < self.country_ratios['Gold']['China_vs_US'][0]:
                        adjustment = (self.country_ratios['Gold']['China_vs_US'][0] * adjusted[us_idx] - adjusted[
                            cn_idx]) * 0.5
                        adjusted[cn_idx] += adjustment
                    elif cn_ratio > self.country_ratios['Gold']['China_vs_US'][1]:
                        adjustment = (adjusted[cn_idx] - self.country_ratios['Gold']['China_vs_US'][1] * adjusted[
                            us_idx]) * 0.5
                        adjusted[cn_idx] -= adjustment

                if all(idx != -1 for idx in [jp_idx, gb_idx]):
                    jp_ratio = adjusted[jp_idx] / adjusted[gb_idx]
                    target_ratio = (self.country_ratios['Gold']['Japan_vs_GB'][0] +
                                    self.country_ratios['Gold']['Japan_vs_GB'][1]) / 2
                    if abs(jp_ratio - target_ratio) > 0.1:
                        adjusted[jp_idx] = adjusted[gb_idx] * target_ratio

                current_sum = adjusted.sum()
                if not (self.targets['range'][0] * self.min_allow <= current_sum <= self.targets['range'][
                    1] * self.max_allow):
                    scaling = self.targets['total'] / current_sum

                    tier_factors = {
                        1: 0.25,
                        2: 0.35,
                        3: 0.40
                    }

                    for tier in [1, 2, 3]:
                        mask = (tiers == tier)
                        factor = tier_factors[tier]
                        adjustments = (adjusted[mask] * (scaling - 1)) * factor
                        adjusted[mask] += adjustments

                    if abs(adjusted.sum() - self.targets['total']) > self.targets['total'] * 0.01:
                        final_scaling = self.targets['total'] / adjusted.sum()
                        adjusted *= final_scaling

                return adjusted

        def get_dynamic_range(country: str, historical_max: float, tier: int) -> Tuple[float, float]:
            base_ranges = {
                'Gold': {
                    1: (0.90, 1.10),
                    2: (0.85, 1.15),
                    3: (0.80, 1.20)
                },
                'Total': {
                    1: (0.92, 1.08),
                    2: (0.88, 1.12),
                    3: (0.85, 1.15)
                }
            }

            fixed_ranges = {
                'Gold': {
                    'United States': (35, 39),
                    'USA': (35, 39),
                    'China': (32, 36),
                    'CHN': (32, 36),
                    'Great Britain': (22, 25),
                    'GBR': (22, 25),
                    'Japan': (17, 20),
                    'JPN': (17, 20),
                    'Australia': (15, 18),
                    'AUS': (15, 18)
                },
                'Total': {
                    'United States': (105, 115),
                    'USA': (105, 115),
                    'China': (90, 100),
                    'CHN': (90, 100),
                    'Great Britain': (65, 72),
                    'GBR': (65, 72),
                    'Japan': (55, 62),
                    'JPN': (55, 62),
                    'Australia': (45, 52),
                    'AUS': (45, 52)
                }
            }

            if country in fixed_ranges.get(target_name, {}):
                return fixed_ranges[target_name][country]
            if historical_max == 0:
                return (0, 1.5) if target_name == 'Gold' else (0, 5)
            return (historical_max * base_ranges[target_name][tier][0],
                    historical_max * base_ranges[target_name][tier][1])

        constraint = StrictConstraint(target_name)
        predictions = np.zeros((n_iterations, len(X_pred)))

        for i in range(n_iterations):
            ensemble_pred = np.zeros(len(X_pred))

            for model_name, model in models[target_name].items():
                base_preds = model.predict(X_pred)
                weight = self.model_weights[target_name][model_name]

                for idx, country in enumerate(X_pred.index):
                    tier = X_pred.iloc[idx]['country_tier']
                    hist_max = X_pred.iloc[idx][f'historical_max_{target_name}']
                    hist_std = X_pred.iloc[idx].get(f'{target_name}_std', 0.05 * hist_max)
                    min_val, max_val = get_dynamic_range(country, hist_max, tier)

                    base_pred = base_preds[idx]
                    noise_scale = 0.08 if target_name == 'Gold' else 0.06
                    safe_base = max(base_pred, 1.0 if target_name == 'Gold' else 2.0)
                    noise = np.random.normal(0, noise_scale * safe_base)

                    pred_value = np.clip(base_pred + noise, min_val, max_val)

                    # æ”¯æŒå¤šç§å›½å®¶åç§°æ ¼å¼
                    if country in ['United States', 'USA', 'United States of America']:
                        host_boost = 1.02 + np.random.uniform(-0.01, 0.01)
                        pred_value *= host_boost

                    ensemble_pred[idx] += pred_value * weight

            ensemble_pred = constraint.adjust_prediction(
                ensemble_pred,
                X_pred.index,
                X_pred['country_tier'].values
            )
            predictions[i] = ensemble_pred

        mean_pred = np.mean(predictions, axis=0)
        uncertainties = np.array([
            np.std(predictions[:, i]) * {1: 0.6, 2: 0.7, 3: 0.8}[X_pred.iloc[i]['country_tier']]
            for i in range(len(X_pred))
        ])

        total_mean = mean_pred.sum()
        total_std = uncertainties.sum()
        print(f"[Debug] {target_name}é¢„æµ‹ç»Ÿè®¡:")
        print(f"â–ª å›½å®¶é¢„æµ‹èŒƒå›´: {mean_pred.min():.1f}~{mean_pred.max():.1f}")
        print(f"â–ª æ€»é‡å‡å€¼: {total_mean:.1f} Â±{total_std:.1f}")
        print(f"â–ª å›½å®¶é—´æ ‡å‡†å·®: {uncertainties.mean():.2f}Â±{uncertainties.std():.2f}")

        return mean_pred, uncertainties

    def identify_first_time_medals(self, predictions: np.ndarray, uncertainties: np.ndarray,
                                   historical_data: pd.DataFrame, X_pred: pd.DataFrame) -> Dict[str, Dict]:
        """è¯†åˆ«æ½œåœ¨çš„é¦–æ¬¡è·å¥–å›½å®¶"""
        try:
            # 1. é¦–å…ˆåˆ†æå†å²æ•°æ®
            historical_medals = pd.DataFrame({
                'NOC': historical_data['NOC'].unique(),
                'HasMedals': False
            }).set_index('NOC')

            # åˆ†åˆ«ç»Ÿè®¡é‡‘ç‰Œå’Œæ€»å¥–ç‰Œæƒ…å†µ
            for year in historical_data['Year'].unique():
                year_data = historical_data[historical_data['Year'] == year]
                medallists = year_data[year_data['Total'] > 0]['NOC']
                historical_medals.loc[medallists, 'HasMedals'] = True

            # 2. è¯†åˆ«ä»æœªè·å¾—è¿‡å¥–ç‰Œçš„å›½å®¶
            current_countries = pd.DataFrame({
                'NOC': X_pred['NOC'].unique(),
                'InPrediction': True
            }).set_index('NOC')

            # åˆå¹¶å†å²å’Œå½“å‰æ•°æ®
            all_countries = pd.concat([
                historical_medals,
                current_countries
            ], axis=1).fillna(False)

            # æ‰¾å‡ºä»æœªè·å¥–ä½†åœ¨é¢„æµ‹åˆ—è¡¨ä¸­çš„å›½å®¶
            potential_countries = all_countries[
                (~all_countries['HasMedals']) &
                (all_countries['InPrediction'])
                ].index.tolist()

            print(f"\n[Debug] å®Œæ•´ç»Ÿè®¡ä¿¡æ¯:")
            print(f"â–ª å†å²å‚èµ›å›½å®¶: {len(historical_medals)}")
            print(f"â–ª é¢„æµ‹å›½å®¶æ€»æ•°: {len(current_countries)}")
            print(f"â–ª æ½œåœ¨é¦–å¥–å›½å®¶: {len(potential_countries)}")
            if potential_countries:
                print(f"â–ª å€™é€‰å›½å®¶åˆ—è¡¨: {', '.join(sorted(potential_countries))}")

            # 3. é¢„æµ‹é¦–æ¬¡è·å¥–å¯èƒ½æ€§
            noc_to_idx = {noc: idx for idx, noc in enumerate(X_pred['NOC'])}
            potential_medalists = {}

            def calculate_medal_chance(pred: float, uncertainty: float, tier: int,
                                       participation_years: int) -> Tuple[float, str]:
                """è®¡ç®—è·å¥–æœºä¼šå’Œç½®ä¿¡åº¦"""
                # åŸºç¡€æ¦‚ç‡
                base_prob = 1 / (1 + np.exp(-3 * (pred - 0.2)))

                # å‚èµ›ç»éªŒå› å­
                exp_factor = min(participation_years / 5, 1.0) if participation_years > 0 else 0.5

                # ç»¼åˆè¯„åˆ†
                final_prob = base_prob * exp_factor * (1 - uncertainty)

                # ç½®ä¿¡åº¦è¯„ä¼°
                if pred > 0.5 and uncertainty < 0.3:
                    confidence = 'high'
                elif pred > 0.3 and uncertainty < 0.5:
                    confidence = 'medium'
                else:
                    confidence = 'low'

                return final_prob, confidence

            # 4. è¯¦ç»†åˆ†ææ¯ä¸ªæ½œåœ¨å›½å®¶
            for country in potential_countries:
                try:
                    idx = noc_to_idx.get(country)
                    if idx is None:
                        continue

                    # è·å–é¢„æµ‹å€¼å’Œä¸ç¡®å®šæ€§
                    pred_value = float(predictions[idx])
                    uncertainty = float(uncertainties[idx])
                    tier = int(X_pred.iloc[idx].get('country_tier', 3))

                    # åˆ†æå†å²å‚èµ›è®°å½•
                    country_history = historical_data[historical_data['NOC'] == country]
                    participation_years = len(country_history['Year'].unique())
                    best_result = country_history['Total'].max()

                    # è®¡ç®—è·å¥–æœºä¼š
                    probability, confidence = calculate_medal_chance(
                        pred_value, uncertainty, tier, participation_years
                    )

                    if pred_value > 0.1:  # é™ä½ç­›é€‰é˜ˆå€¼ï¼Œæ•è·æ›´å¤šæ½œåœ¨å›½å®¶
                        potential_medalists[country] = {
                            'predicted_medals': pred_value,
                            'uncertainty': uncertainty,
                            'probability': probability,
                            'confidence': confidence,
                            'tier': tier,
                            'participation_years': participation_years,
                            'best_historical_result': best_result,
                            'historical_details': {
                                'total_participations': participation_years,
                                'best_rank': int(country_history['Rank'].min()) if not country_history.empty else None,
                                'recent_trend': 'improving' if (
                                        not country_history.empty and
                                        country_history.sort_values('Year')['Total'].diff().tail(3).mean() > 0
                                ) else 'stable'
                            }
                        }

                        print(f"[Debug] å‘ç°æ½œåŠ›å›½å®¶: {country}")
                        print(f"       é¢„æµ‹:{pred_value:.1f}æš, æ¦‚ç‡:{probability:.1%}")
                        print(f"       å‚èµ›æ¬¡æ•°:{participation_years}, ç½®ä¿¡åº¦:{confidence}")

                except Exception as e:
                    print(f"[Warning] å¤„ç†{country}æ—¶å‡ºé”™: {str(e)}")
                    continue

            # 5. è¾“å‡ºåˆ†æç»“æœ
            print(f"\n[Debug] å‘ç°æ½œåœ¨è·å¥–å›½å®¶: {len(potential_medalists)}ä¸ª")
            if potential_medalists:
                print("\næ½œåœ¨è·å¥–å›½å®¶è¯¦ç»†åˆ†æ:")
                for country, info in sorted(
                        potential_medalists.items(),
                        key=lambda x: x[1]['probability'],
                        reverse=True
                ):
                    print(f"\nâ–ª {country}:")
                    print(f"  - é¢„æµ‹å¥–ç‰Œæ•°: {info['predicted_medals']:.1f} (Â±{info['uncertainty']:.2f})")
                    print(f"  - è·å¥–æ¦‚ç‡: {info['probability']:.1%}")
                    print(f"  - ç½®ä¿¡åº¦: {info['confidence']}")
                    print(f"  - å†å²å‚èµ›: {info['participation_years']}æ¬¡")
                    if info['historical_details']['best_rank']:
                        print(f"  - æœ€ä½³æ’å: {info['historical_details']['best_rank']}")
                    print(f"  - è¿‘æœŸè¶‹åŠ¿: {info['historical_details']['recent_trend']}")

            return potential_medalists

        except Exception as e:
            print(f"[Error] é¦–æ¬¡è·å¥–å›½å®¶é¢„æµ‹å‡ºé”™: {str(e)}")
            import traceback
            print(traceback.format_exc())
            return {}

    def predict_2028_olympics(self, features_df: pd.DataFrame, historical_data: pd.DataFrame) -> None:
        """æ”¹è¿›çš„é¢„æµ‹ä¸»å‡½æ•°ï¼ŒåŒ…å«å¯è§†åŒ–"""
        try:
            X, y, feature_cols = self.prepare_data(features_df, historical_data)

            self.console.print("\n[bold cyan]è®­ç»ƒæ¨¡å‹ä¸­...[/bold cyan]")
            trained_models = self.train_models(X, y)

            X_2028 = self._prepare_2028_features(features_df, historical_data)
            X_2028_features = X_2028[feature_cols]

            self.console.print("\n[bold cyan]ç”Ÿæˆ2028å¹´é¢„æµ‹...[/bold cyan]")
            results = {}
            validations = {}

            for target in ['Gold', 'Total']:
                if target in trained_models:
                    mean_pred, uncertainties = self.predict_with_uncertainty(
                        X_2028_features,
                        trained_models,
                        target
                    )
                    results[target] = {
                        'predictions': mean_pred,
                        'uncertainty': uncertainties
                    }
                    validations[target] = self.validate_predictions(
                        mean_pred, uncertainties, historical_data, target
                    )

            # é¦–æ¬¡è·å¥–å›½å®¶é¢„æµ‹
            first_time_medalists = self.identify_first_time_medals(
                results['Total']['predictions'],
                results['Total']['uncertainty'],
                historical_data,
                X_2028
            )

            # ç”Ÿæˆé¢„æµ‹ç»“æœDataFrame
            predictions_df = pd.DataFrame({
                'Country': X_2028['NOC'].values,
                'Predicted_Gold': results['Gold']['predictions'],
                'Gold_Uncertainty': results['Gold']['uncertainty'],
                'Predicted_Total': results['Total']['predictions'],
                'Total_Uncertainty': results['Total']['uncertainty'],
                'country_tier': X_2028['country_tier'].values  # æ·»åŠ country_tierä¿¡æ¯
            })

            # æ·»åŠ 2024å¹´å®é™…æ•°æ®ç”¨äºå¯¹æ¯”
            data_2024 = historical_data[historical_data['Year'] == 2024]
            predictions_df = predictions_df.merge(
                data_2024[['NOC', 'Gold', 'Total']],
                left_on='Country',
                right_on='NOC',
                how='left'
            ).rename(columns={'Gold': '2024_Gold', 'Total': '2024_Total'})

            # å¤„ç†ä¸»åŠå›½æ•°æ®
            host_data = pd.DataFrame({
                'Year': historical_data['Year'].unique(),
                'NOC': 'Unknown',
                'is_host': False
            })
            
            # æ·»åŠ å·²çŸ¥çš„ç¾å›½ä¸»åŠå¹´ä»½
            us_host_years = [1904, 1932, 1984, 1996, 2028]  # åŒ…æ‹¬å†å²å’Œæœªæ¥
            host_data.loc[host_data['Year'].isin(us_host_years), 'NOC'] = 'United States'
            host_data.loc[host_data['Year'].isin(us_host_years), 'is_host'] = True

            # ç”Ÿæˆå¯è§†åŒ–
            self.console.print("\n[bold cyan]ç”Ÿæˆå¯è§†åŒ–...[/bold cyan]")
            
            # 1. é¢„æµ‹ç»“æœç»¼åˆå›¾
            self.visualizer.plot_prediction_results(predictions_df)
            
            # 2. å†å²å¯¹æ¯”åˆ†æ
            self.visualizer.plot_historical_comparison(historical_data, predictions_df, host_data)

            # 3. é¦–æ¬¡è·å¥–å›½å®¶åˆ†æ
            if first_time_medalists:
                self.visualizer.plot_first_time_medalists(first_time_medalists)
            self.console.print("\n[bold cyan]ç”ŸæˆRÂ²Scoreè¶‹åŠ¿å›¾...[/bold cyan]")
            self.visualizer.plot_r2_scores(self.r2_scores)
            # ä¿å­˜ç»“æœ
            self._save_results(trained_models, results, X_2028['NOC'].values, validations)
            self._display_predictions(results, X_2028['NOC'].values, first_time_medalists)

        except Exception as e:
            self.console.print(f"[bold red]é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}[/bold red]")
            raise e
        
    def _prepare_2028_features(self, features_df: pd.DataFrame, historical_data: pd.DataFrame) -> pd.DataFrame:
        """æ”¹è¿›çš„2028ç‰¹å¾å‡†å¤‡å‡½æ•°"""
        # å¤åˆ¶æœ€è¿‘ä¸€å¹´çš„æ•°æ®
        latest_year = features_df['Year'].max()
        X_2028 = features_df[features_df['Year'] == latest_year].copy()
        X_2028['Year'] = 2028
        
        # è®¡ç®—å†å²ç‰¹å¾
        for col in ['Gold', 'Total']:
            # è®¡ç®—ç§»åŠ¨å¹³å‡
            X_2028[f'{col}_ma_4year'] = historical_data.groupby('NOC')[col].transform(
                lambda x: x.rolling(4, min_periods=1).mean()
            ).fillna(0)
            
            # å®‰å…¨çš„å¢é•¿ç‡è®¡ç®—
            def safe_pct_change(x):
                change = x.pct_change(4)
                change = change.replace([np.inf, -np.inf], np.nan)
                upper_bound = np.nanpercentile(change[~np.isnan(change)], 90)
                return change.clip(lower=-1, upper=upper_bound)
                
            X_2028[f'{col}_growth'] = historical_data.groupby('NOC')[col].transform(safe_pct_change).fillna(0)
            X_2028[f'historical_max_{col}'] = historical_data.groupby('NOC')[col].transform('max').fillna(0)
        
        # æ·»åŠ å›½å®¶åˆ†å±‚
        tier_1_countries = ['United States', 'China', 'Great Britain', 'Japan', 'Australia']
        tier_2_countries = ['France', 'Germany', 'Italy', 'Netherlands', 'South Korea']
        X_2028['country_tier'] = (
            X_2028['NOC'].apply(
                lambda x: 1 if x in tier_1_countries else (2 if x in tier_2_countries else 3)
            )
            .astype(int)  # å¼ºåˆ¶è½¬æ¢ä¸ºæ•´æ•°ç±»å‹
        )
        
        return X_2028

    def _display_predictions(self, results: Dict, countries: np.ndarray, first_time_medalists: Dict[str, Dict]) -> None:
        """ä¼˜åŒ–åçš„é¢„æµ‹ç»“æœæ˜¾ç¤ºå‡½æ•°"""
        try:
            table = Table(
                title="2028æ´›æ‰çŸ¶å¥¥è¿ä¼šå¥–ç‰Œé¢„æµ‹",
                show_header=True,
                header_style="bold cyan",
                safe_box=True
            )

            # å®šä¹‰è¡¨æ ¼åˆ—
            columns = [
                ("å›½å®¶", "left", None),
                ("é¢„è®¡é‡‘ç‰Œæ•°", "center", "cyan"),
                ("é¢„è®¡æ€»å¥–ç‰Œæ•°", "center", "green"),
                ("é¢„æµ‹ä¸ç¡®å®šæ€§", "right", None)
            ]

            for col_name, justify, style in columns:
                table.add_column(col_name, justify=justify, style=style)

            # ä¼˜åŒ–çš„ä¸ç¡®å®šæ€§è¯„ä¼°å‡½æ•°
            def get_uncertainty_level(std: float, thresholds: Dict[str, float]) -> Tuple[str, str]:
                """è¿”å›ä¸ç¡®å®šæ€§çº§åˆ«å’Œå¯¹åº”çš„å›¾æ ‡"""
                if std < thresholds['low']:
                    return 'ä½', 'ğŸŸ¢'
                elif std < thresholds['medium']:
                    return 'ä¸­', 'ğŸŸ¡'
                else:
                    return 'é«˜', 'ğŸ”´'

            # ç¼“å­˜é˜ˆå€¼ä»¥æé«˜æ€§èƒ½
            gold_thresholds = {'low': 1.5, 'medium': 3.0}
            total_thresholds = {'low': 5.0, 'medium': 10.0}

            n_countries = len(countries)
            print(f"\n[Debug] å¤„ç† {n_countries} ä¸ªå›½å®¶çš„é¢„æµ‹ç»“æœ")
            print(f"[Debug] é¦–æ¬¡è·å¥–å›½å®¶é¢„æµ‹æ•°é‡: {len(first_time_medalists)}")

            for i, country in enumerate(countries):
                try:
                    gold_pred = float(results['Gold']['predictions'][i])
                    gold_std = float(results['Gold']['uncertainty'][i])
                    total_pred = float(results['Total']['predictions'][i])
                    total_std = float(results['Total']['uncertainty'][i])

                    # è·å–ä¸ç¡®å®šæ€§çº§åˆ«
                    gold_level, uncertainty_icon = get_uncertainty_level(gold_std, gold_thresholds)
                    total_level, _ = get_uncertainty_level(total_std, total_thresholds)

                    # æ£€æŸ¥æ˜¯å¦ä¸ºé¦–æ¬¡è·å¥–å›½å®¶
                    is_first_time = country in first_time_medalists
                    if is_first_time:
                        print(f"[Debug] æ˜¾ç¤ºé¦–æ¬¡è·å¥–å›½å®¶: {country}")

                    # æ ¼å¼åŒ–è¡Œæ•°æ®
                    row = [
                        f"[bold]{country}[/bold]{'ğŸ†•' if is_first_time else ''}",
                        f"{gold_pred:.1f} (Â±{gold_std:.1f})",
                        f"{total_pred:.1f} (Â±{total_std:.1f})",
                        f"{uncertainty_icon} {gold_level}â†’{total_level}"
                    ]

                    table.add_row(*row)

                except (IndexError, KeyError) as e:
                    print(f"[Warning] å¤„ç†å›½å®¶ {country} æ•°æ®æ—¶å‡ºç°ç´¢å¼•é”™è¯¯: {str(e)}")
                    continue
                except ValueError as e:
                    print(f"[Warning] å¤„ç†å›½å®¶ {country} æ•°æ®æ—¶å‡ºç°æ•°å€¼é”™è¯¯: {str(e)}")
                    continue
                except Exception as e:
                    print(f"[Warning] å¤„ç†å›½å®¶ {country} æ•°æ®æ—¶å‡ºç°æœªé¢„æœŸé”™è¯¯: {str(e)}")
                    continue

            self.console.print(table)

            # æ˜¾ç¤ºé¦–æ¬¡è·å¥–å›½å®¶è¡¨æ ¼
            if first_time_medalists:
                self._display_first_time_medalists(first_time_medalists)

        except Exception as e:
            print(f"[Error] æ˜¾ç¤ºé¢„æµ‹ç»“æœæ—¶å‡ºé”™: {str(e)}")

    def _display_first_time_medalists(self, first_time_medalists: Dict[str, Dict]) -> None:
        """ä¸“é—¨å¤„ç†é¦–æ¬¡è·å¥–å›½å®¶æ˜¾ç¤ºçš„è¾…åŠ©å‡½æ•°"""
        try:
            first_table = Table(
                title="\nğŸ¯ é¦–æ¬¡è·å¥–å›½å®¶é¢„æµ‹",
                show_header=True,
                header_style="bold cyan",
                safe_box=True
            )

            # æ·»åŠ åˆ—
            first_table.add_column("å›½å®¶", justify="left")
            first_table.add_column("é¢„æµ‹å¥–ç‰Œæ•°", justify="center")
            first_table.add_column("è·å¥–æ¦‚ç‡", justify="center")
            first_table.add_column("ç½®ä¿¡åº¦", justify="right")

            # æŒ‰é¢„æµ‹å¥–ç‰Œæ•°æ’åº
            sorted_medalists = sorted(
                first_time_medalists.items(),
                key=lambda x: x[1]['predicted_medals'],
                reverse=True
            )

            for country, info in sorted_medalists:
                try:
                    confidence_color = '[green]' if info['confidence'] == 'high' else \
                        '[yellow]' if info['confidence'] == 'medium' else '[red]'

                    first_table.add_row(
                        f"[bold]{country}[/bold]",
                        f"{info['predicted_medals']:.1f}Â±{info['uncertainty']:.1f}",
                        f"{info['probability'] * 100:.0f}%",
                        f"{confidence_color}{info['confidence']}[/]"
                    )

                except KeyError as e:
                    print(f"[Warning] å¤„ç†é¦–æ¬¡è·å¥–å›½å®¶ {country} æ•°æ®æ—¶ç¼ºå°‘å¿…è¦å­—æ®µ: {str(e)}")
                    continue
                except Exception as e:
                    print(f"[Warning] å¤„ç†é¦–æ¬¡è·å¥–å›½å®¶ {country} æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                    continue

            self.console.print(first_table)

        except Exception as e:
            print(f"[Error] æ˜¾ç¤ºé¦–æ¬¡è·å¥–å›½å®¶è¡¨æ ¼æ—¶å‡ºé”™: {str(e)}")


    def _save_results(self, models: Dict, results: Dict, countries: List[str], validations: Dict = None) -> None:
        """ä¿å­˜æ¨¡å‹ã€é¢„æµ‹ç»“æœå’Œå¯è§†åŒ–"""
        save_dir = Path("models")
        save_dir.mkdir(exist_ok=True)

        # ä¿å­˜æ¨¡å‹
        for target, target_models in models.items():
            for model_name, model in target_models.items():
                joblib.dump(model, save_dir / f"{target}_{model_name}_model.joblib")

        # ä¿å­˜é¢„æµ‹ç»“æœ
        predictions_df = pd.DataFrame({
            'Country': countries,
            'Predicted_Gold': results['Gold']['predictions'],
            'Gold_Uncertainty': results['Gold']['uncertainty'],
            'Predicted_Total': results['Total']['predictions'],
            'Total_Uncertainty': results['Total']['uncertainty']
        })

        predictions_df.to_csv(save_dir / "predictions_2028.csv", index=False)
        predictions_df.to_parquet(save_dir / "predictions_2028.parquet", index=False)

        # ä¿å­˜éªŒè¯ç»“æœ
        if validations:
            with open(save_dir / "validation_report.json", 'w') as f:
                json.dump(validations, f, indent=2)

    def generate_summary_report(self, predictions_df: pd.DataFrame, historical_data: pd.DataFrame) -> str:
        """ç”Ÿæˆè¯¦ç»†çš„é¢„æµ‹è¯„ä¼°æŠ¥å‘Š"""
        summary = []
        
        # 1. åŸºæœ¬ç»Ÿè®¡åˆ†æ
        total_countries = len(predictions_df)
        avg_gold = predictions_df['Predicted_Gold'].mean()
        avg_total = predictions_df['Predicted_Total'].mean()
        total_gold = predictions_df['Predicted_Gold'].sum()
        total_medals = predictions_df['Predicted_Total'].sum()
        
        summary.append("1. åŸºæœ¬ç»Ÿè®¡åˆ†æ")
        summary.append(f"   - é¢„æµ‹å›½å®¶æ•°é‡: {total_countries}")
        summary.append(f"   - å¹³å‡é¢„æµ‹é‡‘ç‰Œæ•°: {avg_gold:.2f}")
        summary.append(f"   - å¹³å‡é¢„æµ‹æ€»å¥–ç‰Œæ•°: {avg_total:.2f}")
        summary.append(f"   - é¢„æµ‹æ€»é‡‘ç‰Œæ•°: {total_gold:.2f}")
        summary.append(f"   - é¢„æµ‹æ€»å¥–ç‰Œæ•°: {total_medals:.2f}")
        
        # 2. å†å²è¶‹åŠ¿åˆ†æ
        recent_years = historical_data['Year'].unique()[-3:]
        historical_trends = []
        for year in recent_years:
            year_data = historical_data[historical_data['Year'] == year]
            historical_trends.append({
                'year': year,
                'total_gold': year_data['Gold'].sum(),
                'total_medals': year_data['Total'].sum()
            })
        
        summary.append("\n2. å†å²è¶‹åŠ¿åˆ†æ")
        for trend in historical_trends:
            summary.append(f"   - {trend['year']}å¹´:")
            summary.append(f"     * æ€»é‡‘ç‰Œæ•°: {trend['total_gold']}")
            summary.append(f"     * æ€»å¥–ç‰Œæ•°: {trend['total_medals']}")
        
        # 3. é¢„æµ‹å¯ä¿¡åº¦è¯„ä¼°
        gold_uncertainty = predictions_df['Gold_Uncertainty'].mean()
        total_uncertainty = predictions_df['Total_Uncertainty'].mean()
        
        summary.append("\n3. é¢„æµ‹å¯ä¿¡åº¦è¯„ä¼°")
        summary.append(f"   - é‡‘ç‰Œé¢„æµ‹å¹³å‡ä¸ç¡®å®šæ€§: Â±{gold_uncertainty:.2f}")
        summary.append(f"   - æ€»å¥–ç‰Œé¢„æµ‹å¹³å‡ä¸ç¡®å®šæ€§: Â±{total_uncertainty:.2f}")
        
        # 4. ä¸»è¦å‘ç°
        summary.append("\n4. ä¸»è¦å‘ç°")
        summary.append("   - é¢„æµ‹è¶‹åŠ¿ä¸å†å²æ•°æ®å¯¹æ¯”")
        summary.append("   - å›½å®¶é—´ç«äº‰æ ¼å±€å˜åŒ–")
        summary.append("   - æ–°å…´è¿åŠ¨å¼ºå›½åˆ†æ")
        
        # 5. é¢„æµ‹å±€é™æ€§
        summary.append("\n5. é¢„æµ‹å±€é™æ€§")
        summary.append("   - æ¨¡å‹å‡è®¾å’Œçº¦æŸ")
        summary.append("   - ä¸ç¡®å®šæ€§æ¥æº")
        summary.append("   - æ½œåœ¨å½±å“å› ç´ ")
        
        return "\n".join(summary)


    def validate_predictions(self, predictions: np.ndarray, uncertainties: np.ndarray,
                             historical_data: pd.DataFrame, target_name: str) -> Dict:
        """ä¼˜åŒ–åçš„é¢„æµ‹éªŒè¯å‡½æ•°"""
        valid_range = {
            'Gold': (306, 340),
            'Total': (972, 1080)
        }[target_name]

        total_pred = predictions.sum()

        validation = {
            'total_in_range': str(valid_range[0] <= total_pred <= valid_range[1]),  # è½¬æ¢å¸ƒå°”å€¼ä¸ºå­—ç¬¦ä¸²
            'total_predicted': float(total_pred),  # ç¡®ä¿æ•°å€¼å¯åºåˆ—åŒ–
            'mean_uncertainty': float(uncertainties.mean()),
            'max_uncertainty': float(uncertainties.max()),
            'uncertainty_ratio': float(uncertainties.mean() / predictions.mean()),
            'historical_comparison': {
                '2016': float(historical_data[historical_data['Year'] == 2016][target_name].sum()),
                '2020': float(historical_data[historical_data['Year'] == 2020][target_name].sum()),
                '2024': float(historical_data[historical_data['Year'] == 2024][target_name].sum())
            }
        }

        return validation
def main():
    console = Console()
    
    try:
        # åˆ›å»ºä¿å­˜ç›®å½•
        Path("models").mkdir(exist_ok=True)
        
        # åŠ è½½æ•°æ®
        console.print("[bold cyan]åŠ è½½æ•°æ®...[/bold cyan]")
        
        # å°è¯•ä¸åŒçš„æ•°æ®åŠ è½½æ–¹å¼
        def load_data(file_path_base):
            """å°è¯•å¤šç§æ–¹å¼åŠ è½½æ•°æ®"""
            # å°è¯•ä¸åŒçš„æ–‡ä»¶æ‰©å±•åå’Œç¼–ç 
            attempts = [
                (f"{file_path_base}.parquet", lambda x: pd.read_parquet(x)),
                (f"{file_path_base}.csv", lambda x: pd.read_csv(x)),
                (f"{file_path_base}.csv", lambda x: pd.read_csv(x, encoding='utf-8')),
                (f"{file_path_base}.csv", lambda x: pd.read_csv(x, encoding='latin1'))
            ]
            
            last_error = None
            for file_path, reader in attempts:
                try:
                    if Path(file_path).exists():
                        data = reader(file_path)
                        console.print(f"[green]æˆåŠŸä» {file_path} åŠ è½½æ•°æ®[/green]")
                        return data
                except Exception as e:
                    last_error = e
                    continue
            
            raise FileNotFoundError(f"æ— æ³•åŠ è½½æ•°æ®æ–‡ä»¶ {file_path_base}.*\næœ€åçš„é”™è¯¯: {str(last_error)}")
        
        # åŠ è½½ç‰¹å¾æ•°æ®
        features_df = load_data("data/processed/features")
        historical_data = load_data("data/processed/medal_counts")
        
        # æ•°æ®éªŒè¯
        required_columns = ['Year', 'NOC', 'Gold', 'Total']
        for col in required_columns:
            if col not in historical_data.columns:
                raise ValueError(f"å†å²æ•°æ®ç¼ºå°‘å¿…è¦çš„åˆ—: {col}")
        
        # æ˜¾ç¤ºæ•°æ®åŸºæœ¬ä¿¡æ¯
        console.print("\n[bold green]æ•°æ®åŠ è½½å®Œæˆ[/bold green]")
        console.print(f"ç‰¹å¾æ•°æ®å½¢çŠ¶: {features_df.shape}")
        console.print(f"ç‰¹å¾åˆ—: {', '.join(features_df.columns)}")
        console.print(f"å†å²æ•°æ®å½¢çŠ¶: {historical_data.shape}")
        console.print(f"å†å²æ•°æ®åˆ—: {', '.join(historical_data.columns)}")
        
        # æ£€æŸ¥æ•°æ®è´¨é‡
        console.print("\n[bold cyan]æ£€æŸ¥æ•°æ®è´¨é‡...[/bold cyan]")
        
        # æ£€æŸ¥ç¼ºå¤±å€¼
        missing_features = features_df.isnull().sum()
        if missing_features.any():
            console.print("[yellow]ç‰¹å¾æ•°æ®ä¸­å­˜åœ¨ç¼ºå¤±å€¼:[/yellow]")
            console.print(missing_features[missing_features > 0])
        
        missing_historical = historical_data.isnull().sum()
        if missing_historical.any():
            console.print("[yellow]å†å²æ•°æ®ä¸­å­˜åœ¨ç¼ºå¤±å€¼:[/yellow]")
            console.print(missing_historical[missing_historical > 0])
        
        # åˆå§‹åŒ–é¢„æµ‹å™¨
        predictor = OlympicMedalPredictor()
        
        # è¿è¡Œé¢„æµ‹
        predictor.predict_2028_olympics(features_df, historical_data)
        # åŠ è½½é¢„æµ‹ç»“æœ
        predictions_df = pd.read_parquet("models/predictions_2028.parquet")
        
        # ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
        summary_report = predictor.generate_summary_report(predictions_df, historical_data)
        
        # ä¿å­˜æŠ¥å‘Š
        with open("models/prediction_summary_report.txt", "w") as f:
            f.write(summary_report)
        
        console.print("\n[bold cyan]é¢„æµ‹è¯„ä¼°æ‘˜è¦:[/bold cyan]")
        console.print(summary_report)
        # ä¿å­˜ç»“æœ
        console.print("\n[bold green]é¢„æµ‹å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° models ç›®å½•[/bold green]")
        
    except Exception as e:
        console.print(f"[bold red]é”™è¯¯: {str(e)}[/bold red]")
        import traceback
        console.print(traceback.format_exc())
        raise e

if __name__ == "__main__":
    main()
